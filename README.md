## 前提声明
这个项目是一个简单的集装箱编号识别内核，实际上就是一个应付作业的缝合怪，但是笔者认为它还是有一定的参考价值的。  
整体上来说，它接收一张包含集装箱编号的图片，输出图片上的集装箱编号（不一定正确）。它通过如下三个过程来实现集装箱编号的识别，识别流程为：  
集装箱编号区域定位、编号字符分割、编号字符识别。  

注：我再次声明：这个项目我认为并不优秀，甚至可以说是一坨屎，但是我为它投入了不少精力，我认为依然有一些可取的东西，即可以用来参考，希望这能帮到你  

其中，集装箱编号区域定位使用的是基于改进的yolov5算法进行，yolov5适用于这种图片上的小对象检测，而集装箱编号一般情况下就属于这种小对象。
具体的理论流程我也不懂，我就是直接使用为了完成任务的，大家如果想深入学习可以自己在网上查找资料。我从实践层面上给大家介绍一下。  
1）在定位编号区域模型的训练过程中，运行项目文件夹下的train.py脚本，运行命令如下：
```
python train.py --weights yolov7x.pt --cfg cfg/training/yolov7-up.yaml --data data/up.yaml --batch-size 3 --epoch 300 --device 0
```
之后会在runs文件夹下的train文件夹的最新文件夹内找到新生成的best.py文件，将其拷贝到项目文件夹下，作为定位编号区域的模型。  
在定位编号区域的检测阶段，就是上手使用训练的模型去定位编号区域，使用detect.py脚本，可以通过命令：
```
python detect.py --weights best.pt --source xxx --device 0
```
来定位相应图片的编号区域，也可以切换处理图片的路径，打开相应脚本直接运行来定位图片，定位后的结果会存放到runs文件夹下的detect文件夹新生成的文件夹中，同时还会有一个labels文件夹，里面存放生成的检测框的坐标信息，以用于后续的编号区域的裁剪  
2）用yolov5定位编号区域后，接着使用cut.py脚本，可以使用命令：
```
python cut.py --source XXXX --label XXXXX
```
来裁剪编号区域图片，也可以调整相应参数，直接运行脚本裁剪编号区域图片，得到的结果会存放到cropped_images文件夹中
3）裁剪所得的编号区域图片是彩色的，彩色背景的处理是比较复杂的，又因为我们的字符分割和字符识别本质上关心的还是字符的位置和形态，其实只需要能够区分字符和背景就行，所以我们先要对编号区域图片进行形态学预处理操作（本质上就是二值化），使用的脚本是pretreat.py脚本，可以执行命令：
```angular2html
python pretreat.py --source XXXX
```
来读取cropped_images中要处理的编号区域图片，输出文件存放到binary_images中  
4）形态学预处理后得到的图片是白色字符、黑色背景的图片，之后要次进行字符分割，分割使用的脚本是devide.py（基于连通域分析法的字符分割），运行命令如下：
```angular2html
python devide.py --source XXXX
```
也可以指定存储在binary_images中的二值化图片，直接运行脚本得到分割的结果，分割的结果会存储在singledigit文件夹中，其中的每个子文件夹都是以图片名字命名的  
5）字符分割后使用recognition.py脚本来识别编号字符，需要传入singledigit中的子文件夹的路径，然后它会使用运行recog_train.py脚本训练得到的LeNet70.pth权重文件来识别编号字符，最终输出编号字符串。  
注：识别的结构可能不准，需要后续在Java模块中校验并纠正一下，另外，在纠正后，要意识到对于集装箱编号中最后一位字符的识别是不准确的。我参考这个https://www.jianshu.com/p/272a44381911，即根据前10位编号计算出最后一位校验码，完成识别过程  

* 参考链接：我和抱歉，本来我应该给大家提供一个搭建yolov5的环境的参考链接来着，但是当我写这篇文章的时候，那个链接已经404了，所以大家各显神通吧，祝好运。  
* 在搭建好yolov5的运行环境后，从下面GitHub代码地址获取代码：https://github.com/CaoY123456/container-number-identification.git  
* 拉取代码后，用PyCharm导入项目，需要导入相关包（这个过程会有点劝退人，尤其是涉及到版本冲突的问题，需要耐心搜索一下）  
* 在导入相关包后，要想运行这些代码，还需要从百度网盘下载一些文件，包括一些图片文件，实验中间的数据以及训练出来的权重文件，很多东西是有点不必要的，但是我还是把它保留了  
* 运行该内核代码必要文件：（需要解压后放在项目文件夹下）  
链接：https://pan.baidu.com/s/1eouKAbyrhe6nAiYw_ce4gw   
提取码：hhxx 
* 在将所有的文件都准备好后，我们来看一下各个文件和脚本的作用：  
-- bak文件夹：备份文件夹，当时为了暂存一些脚本和图片用于比对用的，没什么用  
-- binary_images文件夹：保存二值化后的文件夹，是pretreat.py脚本运行后的输出，是devide.py系列脚本的输入  
-- cfg文件夹：是原来那个yolo项目的配置的文件夹，就是这个项目：https://github.com/CaoY123456/yolov7.git  
-- cropped_images文件夹：保存的是经过yolov5找到集装箱编号区域后裁剪的图片，是pretreat.py执行脚本输入读入的文件夹  
-- data文件夹，上述我参考的yolo项目原来带有的一些配置文件，可以按照上面那个链接参考一下  
-- data_enhance文件夹：数据增强文件夹，存放的是yolov5训练模型的时候针对数据增强的效果，这个文件夹并不是运行yolov5训练代码时序偶需要的，而是笔者写关于这个毕设的报告时写的，其中：  
  （1）blur文件夹存储到对图片模糊处理后的结果图  
  （2）hsv_enhance文件夹存储的是对图片进行颜色空间增强的结果图  
  （3）mosaic文件夹存储的是对图片进行马赛克增强的结果图  
  （4）random_affine_transformation文件夹存储的是对图片进行各种随机仿射变换的各种图片  
-- datasets存储的用于训练和测试的图片数据以及相应的标签文件，其中：  
  （1）images文件夹中的train和val文件夹都是集装箱图片（用于yolov5区域定位的），只不过前一个是训练集，另一个是验证集  
  （2）labels文件夹中存放的则是使用labelImg工具用yolo格式标注图片生成的标签文件  
  （3）test中存放的则是在训练完yolov5识别模型后，我选取一些图片放入其中测试模型的准确率的图片  
-- deploy文件夹：原有的yolov5项目的文件夹  
-- figure文件夹：原有的yolov5项目的文件夹
-- fonts文件夹：存储各种windows字体的文件，在最初训练基于LeNet识别单个编号字符的时候，我是自己生成不同字体的编号字符额二值化图片来训练模型的，但是后来又直接去找了现成的数据集，加工了一下就可以用了，所以严格来说这个文件夹也没有什么大用  
-- generated_images文件夹：原来存储的是我自己通过编写脚本生成的白色字符、黑色背景的英文和数字的二值化图片，后来存放的就是我找的现成的数据集的图片，基于LeNet神经网络使用的就是这个文件夹的图片  
-- inference文件夹：原有的yolov5项目的文件夹
-- models文件夹：原有的yolov5项目的文件夹
-- paper文件夹：原有的yolov5项目的文件夹，存放的是yolo的一篇英文论文
-- recog_train：历次基于LeNet神经网络训练所得的权重文件，可以用它们来识别单个字符，但是效果不一定好  
-- runs文件夹：存储的是运行基于yolov5代码的训练和编号区域定位的结果，其中：  
  （1）train中存储的是每次训练后的权重文件  
  （2）detect中存储的是每次定位后生成的坐标框文件以及绘制标注框的集装箱编号图片  
-- scripts文件夹：原有的yolov5项目的文件夹  
-- singledigit文件夹：存储的是经过字符分割后的每张图片的单个字符的情况  
-- utils：原有的yolov5项目的文件夹，存储的是一些python工具包    
-- .gitignore：git排除上传远程仓库的文件  
-- best.pt：训练出的效果最好的基于yolov5定位集装箱编区域的模型权重文件  
-- blur.py：对图片模糊处理的脚本  
-- change_data.py：对收集到的要用于训练基于LeNet神经网络模型识别单个编号字符的数据集进行再加工的脚本  
-- config.py：一些公共的配置，方便获取一些常量，但是实际上里面也没有多少东西  
-- cut.py：在基于yolov5算法将集装箱编号区域定位并生成相应的区域框的坐标位置后，这个脚本可以将其中的编号区域裁剪出来，以缩小后续图片处理的范围  
-- detect.py：原有的yolov5项目的脚本，阅读代码可知，将我们训练的权重文件放进去，再传入要处理的集装箱编号图片，就可以定位编号区域，不过也有出错的情况  
-- devide.py、devide2.py、devide3.py：对预处理后编号的二值化编号图片进行分割的脚本，之所以是三个，当时使用了不同的分割策略，分别为：基于连通域分析法、投影法、轮廓检测法寻找编号字符部分，同时尽可能过滤其中的非编号字符部分。经实验结果可得，三者的效果由好到坏分别为：连通域分析法、轮廓检测法、投影法。      
-- export.py：原有的yolov5项目的脚本  
-- generate.py：自己编写的生成用于训练基于LeNet神经网络识别单个编号字符模型所需的白色字符、黑色背景的二值化图片的脚本，但是后来就自己直接找现成的数据集了，所以也没有什么用了  
-- generate_hollow.py：用于生成空心、只含有轮廓的用于LeNet神经网络识别编号字符的白色字符、黑色背景的二值化图片，为什么要写这么一个脚本呢？因为最初探索形态学处理流程的时候，处理出来的字符效果并不好，导致得到的图片中的字符部分通常是一个字符轮廓，所以就需要生成相特征的字符图片去训练模型，但是后面又找到了更好的预处理的算法，使得得到的编号字符是实心的而非轮廓，所以这个脚本实际上也就没什么用了  
-- hello.py：当时为了测试从Java模块编写的代码调用python模块编写代码时所写的一个简单的响应脚本  
-- hsv_enhance.py：HSV颜色空间增强的脚本，为了汇报实验，说明在yolov5训练的时候所做的HSV颜色空间增强的效果的实现脚本，为了演示，实际上对实验结果没有什么影响，向这种演示类的脚本看看就得了，笔者训练的时候就是无脑莽  
-- hubconf.py：原有的yolov5项目的脚本  
-- last.pt：和best.pt差不多，也是yolov5训练出来的模型，只不过我使用了best.pt作为权重文件，当然你也可以用last.pt，个人认为区别不大  
-- *.pth：以.pth结尾的文件都是运行recog_train.py脚本训练出来的基于LeNet神经网络识别编号字符的模型文件，但是怎么说呢？这些效果都不好，也就LeNet70.pth的识别效果好一点，其他的都一般  
-- main.py：这是一个核心的脚本，串联起所有过程，包括集装箱编号区域的定位、编号字符分割、编号字符识别的整个流程，直接运行这个就可以了，但是由于我这个是被内核的通用性比较差，所以可能会中途报错而卡住  
-- mosaic.py：与hsv_enhance.py类似，是用于对图片进行马赛克增强的脚本  
-- pretreat.py：用于形态学预处理的脚本，这个是我本人的杰作，是我在这个项目中探索时间最长的东西，虽然不能完全做到通用性，但是它也已经很好了，它会输出一张白色字符、黑色背景的二值化图片  
-- random_affine_transformation.py：与hsv_enhance.py类似，是用于对图片进行随机仿射变换增强的脚本  
-- recog_train.py：基于LeNet神经网络识别编号字符的训练脚本，是输出识别模型的脚本  
-- recog_train2.py：基于比LeNet更复杂的神经网络训练识别编号字符模型的脚本。因为当时LeNet的训练的效果并不好，想换个更复杂的模型来改进一下，奈何我电脑GPU内存太小，跑不起来，故只能作罢  
-- recognition.py：使用由recog_train.py训练出来的识别模型，同样基于LeNet神经网络去识别已经分割好的编号字符图片  
-- requirements.txt：记录各种依赖的名称和版本号，不过这个可以不用关心的那么细，大体上，使用的是Minianaconda3管理python环境，python版本为3.7  
-- test.py：原有的yolov5项目的脚本  
-- traced_model.pt：原有的yolov5项目的权重文件  
-- train.py：原有的yolov5项目的训练集装箱编号区域定位的脚本，十分重要  
-- train_aux.py：原有的yolov5项目的脚本  
-- yolov7x.pt：原有的yolov5项目的权重文件，很重要  
1. 使用gpu训练的命令
```
python train.py --weights yolov7x.pt --cfg cfg/training/yolov7-up.yaml --data data/up.yaml --batch-size 3 --epoch 300 --device 0
```
注意上面的 --batch-size 不能设的大了，否则会报内存空间分配不足的 error，经过实践，为1时可以正常运行

注：  
1). 可以通过命令：tensorboard --logdir=runs 来查看训练过程中的日志  
2). 在已经有权重文件的情况下，可以不运行上述命令进行训练 

2. 定位编号区域的命令
```
python detect.py --weights best.pt --source xxx --device 0
```

3. 裁剪已经标定的图片的命令，--source后传入要裁剪的已经有标定框的图片，--label后传入的标定框的坐标文件
```
python cut.py --source XXXX --label XXXXX
```

4. 对于裁剪的图片预处理命令
```angular2html
python pretreat.py --source XXXX
```

5. 对于预处理后的图片进行分割，其中也包含了归一化过程
```angular2html
python devide.py --source XXXX
```